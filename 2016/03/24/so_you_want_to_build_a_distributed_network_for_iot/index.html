<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1"> <title>So You Want to Build a Distributed Network for IoT?</title> <meta name="description" content="In this article, I’ll go through the past 4 months with The Things Network. It aims at givingtechnical and non-technical insights on the project for an exter..."> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="http://ktorz.github.io/2016/03/24/so_you_want_to_build_a_distributed_network_for_iot/"> <link rel="alternate" type="application/rss+xml" title="KtorZ's Blog" href="http://ktorz.github.io/feed.xml"> <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"> <link rel="alternate" type="application/atom+xml" title="" href="http://ktorz.github.io/feed.xml" /> <script src="/assets/js/modernizr.js"></script> <!-- Google Analytics --> </head> <body"> <main class="wrapper"> <header class="site-header"> <a href="#navbar" id="menu-burger" class="menu-burger">Menu <span class="nav-icon"></span> <svg x="0px" y="0px" width="54px" height="54px" viewBox="0 0 54 54"> <circle fill="transparent" stroke="#000000" stroke-width="1" cx="27" cy="27" r="25" stroke-dasharray="157 157" stroke-dashoffset="157"></circle> </svg> </a> <div id="navbar" class="navbar"> <div class="navigation-wrapper"> <div class="half-block"> <h2>Navigation</h2> <nav> <ul class="primary-nav"> <li><a href="/">Blog</a></li> <li><a href="/references">References</a></li> <li><a href="/about">About</a></li> <li><a href="http://github.com/KtorZ" target="_blank"><i class="icon icon-github"></i> Github</a></li> <li><a href="http://linkedin.com/in/matthias-benkort-47186a57" target="_blank"><i class="icon icon-linkedin"></i> LinkedIn</a></li> <li><a href="/feed.xml" target="_blank"><i class="icon icon-feed"></i> RSS</a></li> </ul> </nav> </div> </div> </div> </header> <article class="post" itemscope itemtype="http://schema.org/BlogPosting"> <header class="post-header intro"> <div class="intro-in"> <h1 class="post-title" itemprop="name headline">So You Want to Build a Distributed Network for IoT?</h1> <p class="post-meta"><time datetime="2016-03-24T17:33:59+01:00" itemprop="datePublished">Mar 24, 2016</time> • <span itemprop="author" itemscope itemtype="http://schema.org/Person"><span itemprop="name">Matthias Benkort</span></span></p> </div> </header> <div class="post-content container" itemprop="articleBody"> <p>In this article, I’ll go through the past 4 months with The Things Network. It aims at giving technical and non-technical insights on the project for an external enthusiast or someone willing to catch-up with the work that has already been done.</p> <h2 id="overview-of-the-things-network">Overview of The Things Network</h2> <h3 id="what-is-iot">What is IoT?</h3> <p>The Internet of Things, a.k.a <em>IoT</em>, describes the network made by connected objects. In opposition to the Internet which describes the network of computers (on a very large scale - a <a href="https://www.raspberrypi.org/">Raspberry Pi</a> could be here considered as a computer). Connected objects could be any <em>things</em> such as vehicles, a fridge or your cat (please don’t do that). So far, the idea of a network loosely refers to an abstraction of our vocabulary. There’s actually no such thing as <em>another</em> network; under the bonnet, everything still relies on the mighty Internet. One rather calls IoT the extension created by all those devices. I believe nonetheless in the possibility of an alternative network, dedicated to the <em>things</em>. Almost 50 years after <a href="https://en.wikipedia.org/wiki/ARPANET">ARPANET</a> (the most relevant ancestor of the Internet), it is still unusual to consider making two distant machines communicate with anything else than the standard <code>tcp/ip</code> stack alongside with <code>dns</code>. Yet, researchers and engineers are <a href="https://www.micrium.com/iot/internet-protocols/">already looking forward to build a new stack</a> which could manage traffic more efficiently regarding to <em>things</em>. Aiming at the same direction, The Things Network (hereby known as TTN) strives to build a network for <em>IoT</em>. Even though it still relies on the standard Internet stack, promises are good enough to foresee an evolution towards a parallel and independent dedicated network.</p> <h3 id="ttn">TTN</h3> <p>One does not simply talk about TTN without mentioning <a href="https://www.lora-alliance.org/What-Is-LoRa/Technology">LoRa</a>. Straightforwardly, <em>LoRa</em> stands for <strong>Lo</strong>ng <strong>Ra</strong>nge. It is a low-energy modulation technique for radio signals. It is thereby a core technology on which relies The Things Network. Basically, a slew of <strong>end-devices</strong> can emit signal on a radio frequency using the LoRa modulation in order to be picked up by one or several <strong>Gateway(s)</strong>. Therefore, it enables a huge area to be covered by a tiny amount of gateways and in the meanwhile, it enables the network to spread across the world. Let’s paint a big picture of the network architecture and for that, we’ll consider several top-level components with which the reader (you) may want to become familiar.</p> <p><img src="/img/articles/ttn/overview.png" alt="overview" /></p> <p>To avoid any ambiguity in the document, I’ll consider (and I expect the reader to also consider it) <em>the network</em> to be the combination of <strong>router(s)</strong> + <strong>broker(s)</strong> + <strong>handler(s)</strong> – handlers are not, properly said, part of the network, but stand more like bridges between the network and application. Yet, to keep the discussion simple enough, we’ll consider them as part of it. Therefore, the following document describes The Things Network’s Architecture version 1 which aims at being a scalable, low-latency, distributed and reliable implementation of <a href="https://www.lora-alliance.org/portals/0/specs/LoRaWAN%20Specification%201R0.pdf">LoRaWAN</a>.</p> <h4 id="lorawan-principles">LoRaWAN principles</h4> <p>Before diving a bit more into technical concerns, we need to understand a bit some core concepts of the LoRaWAN protocol. I will save you the time of reading the 82 pages of specifications (I am pretty sure you know better ways to spend your Saturday). Let’s get some directly some insights without scratching too much the surface of it though.</p> <h5 id="frames--messages">Frames &amp; Messages</h5> <p>Packets (or datagrams) flow throughout the network. They carry a payload surrounded by additional pieces of information that are used to conduct this payload from a node to its final recipient. Because payload is a rather general term to describe something carried by an encompassing structure, in LoRaWAN, we called the end payload a <em>frame payload</em>. The network’s role is to make sure that a message received by a gateway arrives, in time, to an application. Because LoRaWAN also allows applications to reply, the network should handle messages from applications to devices. A message going from an end-device towards the application is called an <em>uplink</em> message. The reply is intuitively named a <em>downlink</em>.</p> <p>Besides, messages are encoded, encrypted with a specific key known by the end-devices itself and the application to which it belongs. Providing keys to a device is called <em>activation</em> and LoRaWAN specifies two different ways to eventually provide those keys: the Activation By Personalization (ABP) and the Over-The-Air Activation (OTAA).</p> <h5 id="abp">ABP</h5> <p>The ABP means that a device owns its own keys, since the beginning. They are attached to it and are not configured in any manners. Then, on another level, applications may keep track of which of their devices is associated to which keys.</p> <h5 id="otaa">OTAA</h5> <p>The OTAA is a bit smarter than the ABP. Instead of holding fixed keys, devices hold the logic that allows them to generate them alongside the network. Devices may exchange special messages with the network to establish those keys. The network thereby becomes a mediator between devices and applications in order to set up the initial configuration. The idea behind OTAA is quite powerful. It allows devices to roam easily between different networks and still be able to reach their associated application.</p> <h4 id="node">Node</h4> <p>Nodes or end-devices refer to one end of the chain. End-devices emit signals using LoRa modulation and frequency range towards Gateways. They are split into 3 classes:</p> <ul> <li><strong>A</strong>: Cannot receive any data from the network unless they’ve initiated the communication</li> <li><strong>B</strong>: Can receive data from the network at precisely scheduled windows (Beacons)</li> <li><strong>C</strong>: Can receive data at any time from the network</li> </ul> <p>Incidentally, class A requires less power than B which requires less power than C. An end-device participating in a LoRaWAN network, has a device address and a secret device-specific application session key and network session key. These values are either assigned by the Network or self-defined.</p> <p>These specifications primarily focus on the class A. Future network versions will implement mechanisms to handle class B and class C but they are irrelevant with the current document.</p> <h4 id="gateway">Gateway</h4> <p>Gateways might be seen as a way to transform multiple messages emitters into one much more demanding emitter. Therefore, a Gateway gathers LoRa signals coming from a bunch of near end-devices. A given end-device does not need to know the nearest gateways, nor it has to communicate with a specific one - signals are simply broadcast into the wild open.</p> <p>Gateways receive signals which reach them, and forward all received messages to a dedicated Router. The Data could be either a sensor result or a specific network command such as a connection request. A Gateway actually sends incoming packets to a router after having wrapped each of them into a json structure holding meta-data about the Gateway itself (such as Gateway’s identifier, a timestamp and GPS coordinates if available). Note that a Gateway will forward packets from all LoRA Nodes in its vicinity, even if a Node is not part of the Things Network.</p> <p>Gateways can also emit packets coming from the network toward a Node using the LoRa technology. In fact, Gateways are in charge of taking care of emission at a scheduled time defined by the network meaning that the network is able to send packets to Gateways at any moment, regardless of their emission time.</p> <h4 id="router">Router</h4> <p>Routers are entry points of the network from the Nodes perspective. Packets transmitted by Nodes are forwarded to specific Routers from one or several Gateways. The Router then forwards those packets to one or several Brokers. The communication is bi-directional: Routers may also transfer packets from Broker to Gateways.</p> <p><img src="/img/articles/ttn/uplink_router.png" alt="Uplink forwarding" /></p> <h4 id="broker--network-server">Broker &amp; Network Server</h4> <p>Brokers have a global vision of a network’s part. They are in charge of several nodes, meaning that they will handle packets coming from those nodes (thereby, they are able to tell to Routers if they can handle a given packet). Several Routers may send packets coming from the same end-device (shared by several segments / Gateways), all duplicates are processed by the Broker and are sent to a corresponding Handler.</p> <p>A Broker is thereby able to check the integrity of a received packet and is closely communicating with a Network Server in order to administer the related end-device. For a reference of magnitude, Brokers are designed to be in charge of a whole country or region (if the region has enough activity to deserve a dedicated Broker). Note that while brokers are able to verify the integrity of the packet (and therefore the identity of the end device), they are not able to read application data.</p> <p>Network servers are processing <a href="https://en.wikipedia.org/wiki/Media_access_control">MAC</a> commands emitted by end-devices as well as taking care of the data rates and the frequency of the end-devices. Network Servers would emit commands to optimize the network by adjusting end-devices data rates / frequencies unless the node is requesting to keep its configuration as is.</p> <p>For the moment, a single Network Server will be associated for each Broker. No communication mechanisms between Network Servers is planned for the first version. Also, it won’t be possible for a Broker to query another Network Server than the one it has been assigned to. Those features might be part of a second version. This implies a Broker and a Network Server are, for an external observer, a seemingly unique component. From then on, I’ll consider both of them when referring to a broker.</p> <h4 id="handler">Handler</h4> <p>Handlers materialize the entry point to the network for Applications. They are secure referees which encode and decode data coming from applications before transmitting them to a Broker of the network. Therefore, they are in charge of handling secret applications keys and only communicate an application id to Brokers as well as specific network session keys for each node (described in further sections). This way, the whole chain is able to forward a packet to the corresponding Handler without having any information about either the recipient (but a meaningless id) or the content.</p> <p>Because a given Handler is able to decrypt the data payload of a given packet, it could also implement mechanisms such as geolocation and send to the corresponding application some interesting meta-data alongside the data payload. Incidentally, a handler can only decrypt payload for packets related to applications registered to that handler. The handler is managing several secret application session keys and it uses these to encrypt and decrypt corresponding packet payloads.</p> <p>A Handler could be either part of an application or a standalone trusty server on which applications may register. The Things Network will provide Handlers as part of the whole network but - and this is true for any component - anyone could create its own implementation as long as it is compliant with TTN’s architecture.</p> <h4 id="application">Application</h4> <p>An Application is the owner of an end device in the LoRaWAN model. Applications run outside the Things Network core and interact with it via a handler. As such, applications are responsible for registering their devices with the network via a handler. If not, the device will not be able to join The Things Network.</p> <p><img src="/img/articles/ttn/uplink_broker.png" alt="Uplink to application" /></p> <h2 id="implementations-remarks">Implementations remarks</h2> <p>Before diving into the actual logic implemented in the core components, I want to express some thoughts about subsidiary details on the implementation. The network is a distributed, multi-threaded, low-latency and reliable software, and this implies some extra work to wire up all the different parts such that it seems to make no difference from within the components themselves. Actually, routers don’t care at all about where are located brokers: Should it be the same machine, in the same thread, it won’t make any difference. Also, all components assumed a concurrent environment; they are intended to be used concurrently, and they seemingly expect their dependencies not to flinch when used concurrently.</p> <h3 id="communication-between-services">Communication between services</h3> <p>From an external observer, the network is a big black box with merely two entry points (considering only the main, expected and required features; there’s actually more should one looks at monitoring and meta-information access).</p> <p>The first set of entry points is at the bottom of the network: routers. Each router is listening for <code>udp</code> connections on a given port. Most gateways currently being used forward packets (partially) accordingly to the <a href="https://github.com/TheThingsNetwork/ttn/blob/develop/documents/protocols/semtech.pdf">Semtech protocol</a> which unfortunately relies on <code>udp</code>. We’ll discuss later on what is already planned to replace the current protocol. Therefore, messages can be sent to the network through those <code>udp</code> connections. Eventually, they may be forwarded to applications.</p> <p>On the other hand, the network, as we provide it currently, enables communications directly with handlers. The need of registering devices (for either ABP or OTAA) drives the construction of an API for the handler such that it gives users/developers a bit of control on their nodes among the network. Because we want the communication to be as fast as possible when it comes to nodes, most communications coming from applications are buffered and kept for later use. Thereby, when it comes to register a device, the application let the network knows the target, and the registration, stored, remains in stand-by until the related device shows itself. The devices are, most of the time, the trigger which starts a set of operations within the network. By the way, the communication between applications and TTN handlers is based on <code>rpc</code> over <code>tcp</code>.</p> <p><img src="/img/articles/ttn/services_1.png" alt="TTN Protocols - 1" /></p> <p>One might object the use of<code>rpc</code> between applications and handlers: even though it is a seemly lightweight protocol, it requires an extra effort to set up as well as being quite unusual for web developers. Nevertheless, it also glues the core components of the network, and was therefore a natural choice for us. Moreover, we’re also looking forward to getting rid of <code>udp</code> between gateway and router, and a solution based on <code>rpc</code> could definitely enhance the consistency and robustness of the whole infrastructure.</p> <p><img src="/img/articles/ttn/services_2.png" alt="TTN Protocols - 2" /></p> <p>I should also point out that the use of <code>rpc</code> makes the scattering in micro-services fairly easy. Thereby, all components are arranged in small and isolated micro-services with a tight link to others. From a daemon perspective, it holds a direct reference to another local object on which it might directly and synchronously call methods. Under the hood, each component only holds a stub (a client) which presents the same interface as an external <code>rpc</code> server, listening for <code>tcp</code> requests from other dependent micro-services. One would say the stub is a kind of magic component which interacts with an external server by serializing the request, unserializing the response, and taking care of handling connection establishments and revocations whereas all of this is actually provided by the combination of <a href="http://www.grpc.io/">grpc</a> and <a href="https://developers.google.com/protocol-buffers/">protocol buffers</a>.</p> <p><img src="/img/articles/ttn/services_3.png" alt="TTN Protocols - 3" /></p> <p>As I am writing these words, we’re using the version 3 of the <em>proto</em> language which is still in a beta version of development. Although we’re not making any use of new features introduced in this major, we still want to look forward to possible evolutions; being already compatible with the newest available version makes that move quite logical. Plus, it allows us to optimize the speed and the efficiency of the serialization/unserialization process thanks to <a href="http://gogo.github.io/doc/">gogoprotobuf</a> which provides an incredible set of features on top of <em>proto 3</em>.</p> <p>Besides, while I discussed about the entry points and internal communication in the network, I forgot to mention the network outputs. For those, because we’re likely to find a highly demanding traffic for which a reply is needed within a really short time frame; we cannot expect and require a proportional level of availability from an application. For those reasons, using a publish/subscribe pattern is well indicated. The network can publish regardless of applications states while the latter can process messages at their own pace. <em>mqtt</em> is a strong and reliable protocol which is designed to connect multiple subscribers and publishers altogether.</p> <p>So, we end up with a bunch of micro-services, with which you can interact through <code>rpc</code> over <code>tcp</code> and <code>udp</code> (and hopefully soon only over <code>tcp</code>) and which spit out data in <code>mqtt</code> queues.</p> <p><img src="/img/articles/ttn/services_4.png" alt="TTN Protocols - 4" /></p> <h3 id="concurrent-programming">Concurrent programming</h3> <p>I mentioned above that the application was a multi-threaded software. Since we’re considering a <em>Go</em> context within which several <a href="http://blog.nindalf.com/how-goroutines-work">goroutines</a> live, I would rather talk about a concurrent application. We’ve just seen that TTN is split into several micro-services which behave as independent workers with well defined entry and output paths. Yet, this only reflects the <em>distributed</em> facet of the infrastructure. Each worker actually divides its workload into concurrent and parallel goroutines. It allows multiple requests to be handled simultaneously and also gives us a bit of robustness (a single request might fail and panic without any impact on other requests). Parallelism is not magic though. When it comes to computers, at the very end of the chain, one is just switching a bit from 1 to 0 or 0 to 1; and this cannot be done simultaneously by two different processes, goroutines, threads or whatever they’re called. At some point, one needs to wait and to queue up.</p> <p>How do we handle parallelism in TTN? Firstly: immutability. Secondly: immutability. And thirdly … well, immutability? When one looks at patterns used to manage concurrent processes in a program that might run in parallel, it always ends up to the same idea of <em>critical zones</em>. There’s no way to ensure that a memory space won’t be accessed simultaneously unless you make sure that only one actor can operate on it at a time. This is particularly mandatory when you consider both readings from and writings into that memory space (there’s no issue at all to simultaneously read the same space; it gets more annoying when one’s trying to change what another one is trying to read). Thereby, you either create an artificial safe zone (using semaphores or monitors, we’ll come to that in a minute), or, you simply avoid having shared memory spaces.</p> <p>If you take a quick look at TTN code base, a lot of effort has been done to avoid those pitfalls. Almost all objects that can be instantiated are stateless components. They do not hold any internal state; they do not mutate themselves throughout their life cycle. There’s a huge difference between those two samples:</p> <figure class="highlight"><pre><code class="language-go" data-lang="go"><span class="kd">type</span> <span class="nx">Stateless</span> <span class="kd">struct</span> <span class="p">{}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">s</span> <span class="nx">Stateless</span><span class="p">)</span> <span class="nx">Compute</span><span class="p">(</span><span class="nx">state</span><span class="p">,</span> <span class="nx">v</span> <span class="kt">int</span><span class="p">)</span> <span class="kt">int</span> <span class="p">{</span>
    <span class="c1">// whatever</span>
<span class="p">}</span></code></pre></figure> <figure class="highlight"><pre><code class="language-go" data-lang="go"><span class="kd">type</span> <span class="nx">Stateful</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="nx">state</span> <span class="kt">int</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">s</span> <span class="o">*</span><span class="nx">Stateful</span><span class="p">)</span> <span class="nx">Compute</span><span class="p">(</span><span class="nx">v</span> <span class="kt">int</span><span class="p">)</span> <span class="kt">int</span> <span class="p">{</span>
    <span class="c1">// whatever</span>
<span class="p">}</span></code></pre></figure> <p>The first one can safely be ran in parallel whereas the latter one needs additional internal protections such as <code>mutex</code>. Therefore, objects in TTN are divided in two categories:</p> <ul> <li> <p><strong>Operational objects</strong>: they gather a set of methods under a same label; they are also possibly (and are most of time) composed of other operational objects. They do not carry any data or states except for configuration parameters which <strong>don’t change over time</strong> and are not intended to change <strong>ever</strong>. They assume to be safely used concurrently and simultaneously without any issue.</p> </li> <li> <p><strong>Data objects</strong>: they offer a handy way to aggregate a set of related data that can be manipulated by foreign methods. They do not declare any method except serialization and unserialization methods (marshalling and unmarshalling in the <em>Go</em> vocabulary) that are only used to persist those objects or to send them along remotely. <strong>They’re not intended to be shared by concurrent processes</strong> but are merely a way to friendly pass several parameters to a local (or remote) function within the same execution scope of the calling process itself.</p> </li> </ul> <p>By doing this, we ensure that any operational object can be manipulated simultaneously without the need of setting up a dedicated, restricted concurrent area. As long as they do not mutate any internal state, they might safely be called by thousand actors at the same time. The call itself carries all the data needed and the response illustrates the mutations operated on the inputs. Several consecutive calls with the same inputs lead to the same outputs. There’s no mutation going on and the code is even stronger.</p> <p>Notwithstanding this approach, there are still some cases where it is sometimes needed to operate mutations on an allocated memory space. <em>Go</em> isn’t a functional programming language, hence, it doesn’t offer mechanisms to totally get rid of those mutations (or more exactly, sometimes, it doesn’t fit well to its philosophy). Besides, there’s one adage is <em>Go</em> that says:</p> <blockquote> <p>Do not communicate by sharing memory; instead, share memory by communicating.</p> </blockquote> <p>Having this in mind, I find that <strong>monitors</strong> suit well in the <em>Go</em> paradigm. Monitors describe a nice pattern to isolate a mutable piece of data from concurrent accesses by offering a façade which can be safely accessed simultaneously and which takes care of distributing manipulations of the underlying data it protects. Basically, in <em>Go</em>, it can be implemented really easily using <a href="https://gobyexample.com/channels">channels</a> and function <a href="https://gobyexample.com/closures">closures</a>. It goes like this:</p> <figure class="highlight"><pre><code class="language-go" data-lang="go"><span class="kd">const</span><span class="p">(</span>
    <span class="nx">Add</span> <span class="nx">Order</span> <span class="p">=</span> <span class="kc">iota</span>
    <span class="nx">Sub</span>
<span class="p">)</span>   
<span class="kd">type</span> <span class="nx">Order</span> <span class="kt">byte</span>

<span class="kd">func</span> <span class="nx">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="nx">chorder</span> <span class="o">:=</span> <span class="nb">make</span><span class="p">(</span><span class="kd">chan</span> <span class="nx">Order</span><span class="p">)</span>
    <span class="k">go</span> <span class="nx">monitor</span><span class="p">(</span><span class="nx">chorder</span><span class="p">)</span>
    <span class="nx">chorder</span> <span class="o">&lt;-</span> <span class="nx">Add</span> <span class="c1">// Increase</span>
    <span class="nx">chorder</span> <span class="o">&lt;-</span> <span class="nx">Sub</span> <span class="c1">// Decrease</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nx">monitor</span><span class="p">(</span><span class="nx">chorder</span> <span class="o">&lt;-</span><span class="kd">chan</span> <span class="nx">Order</span><span class="p">)</span> <span class="p">{</span>
    <span class="kd">var</span> <span class="nx">counter</span> <span class="kt">uint</span> <span class="c1">// Variable being monitored</span>
    <span class="k">for</span> <span class="nx">order</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">chorder</span> <span class="p">{</span>
        <span class="k">switch</span> <span class="nx">order</span> <span class="p">{</span>
            <span class="k">case</span> <span class="nx">Add</span><span class="p">:</span>
            <span class="nx">counter</span><span class="o">++</span>
            <span class="k">case</span> <span class="nx">Sub</span><span class="p">:</span>
            <span class="nx">counter</span><span class="o">--</span>
        <span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre></figure> <p>There’s only one goroutine that can access and mutate the <code>counter</code> variable, all other goroutines (the original caller or another subsidiary goroutine, it doesn’t matter) can then safely require mutation by sending orders through the channel. This works well only because channels are concurrent-safe in <em>Go</em> by design. The channel can be accessed by many goroutines, there’s still one single agent that is having control over the variable. The same solution can be implemented with <code>mutex</code> as well (which I find most of the time a bit more inelegant).</p> <figure class="highlight"><pre><code class="language-go" data-lang="go"><span class="kd">type</span> <span class="nx">Monitor</span> <span class="kd">struct</span><span class="p">{</span>
    <span class="nx">sync</span><span class="p">.</span><span class="nx">Mutex</span>
    <span class="nx">counter</span> <span class="kt">uint</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">m</span> <span class="o">*</span><span class="nx">Monitor</span><span class="p">)</span> <span class="nx">Add</span><span class="p">()</span> <span class="p">{</span>
    <span class="nx">m</span><span class="p">.</span><span class="nx">Lock</span><span class="p">()</span>
    <span class="nx">m</span><span class="p">.</span><span class="nx">counter</span><span class="o">++</span>
    <span class="nx">m</span><span class="p">.</span><span class="nx">Unlock</span><span class="p">()</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="p">(</span><span class="nx">m</span> <span class="o">*</span><span class="nx">Monitor</span><span class="p">)</span> <span class="nx">Sub</span><span class="p">()</span> <span class="p">{</span>
    <span class="nx">m</span><span class="p">.</span><span class="nx">Lock</span><span class="p">()</span>
    <span class="nx">m</span><span class="p">.</span><span class="nx">counter</span><span class="o">--</span>
    <span class="nx">m</span><span class="p">.</span><span class="nx">Unlock</span><span class="p">()</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nx">main</span><span class="p">()</span> <span class="p">{</span>
    <span class="nx">monitor</span> <span class="o">:=</span> <span class="nx">Monitor</span><span class="p">{}</span>
    <span class="nx">monitor</span><span class="p">.</span><span class="nx">Add</span><span class="p">()</span>
    <span class="nx">monitor</span><span class="p">.</span><span class="nx">Sub</span><span class="p">()</span>
<span class="p">}</span></code></pre></figure> <p>Choosing one or another is a matter of context. Sometimes, channels make the monitoring really flexible and scalable whereas some other times, mutex just makes it easy to write and to reuse. In the former, the way of communicating is being shared. In the later, that’s the whole data under protection that has to be shared. I would rather go for the solution based on channels as I find it less error-prone and quite effortless to reason about: the data is only manipulated by one agent which is just processing orders sequentially whenever it can. By the way, by using buffered channels, it can also be made completely asynchronous.</p> <h3 id="in-memory-storage">In-memory storage</h3> <p>If it wasn’t clear enough, we’re going to explore the four points I stated in introduction of this section. Should you have followed it correctly, we primarly talked about the <em>distributed</em> aspect of TTN before dealing with the <em>concurrent</em> one. Let’s now glance at the <em>low-latency</em> facet of it. The network, as specified by LoRaWAN should process a message within a short time frame. Technically, LoRaWAN allows the network to configure the frame’s size but let’s assume a default configuration setup and consider that we have to process a packet (ideally) within a second. The processing is distributed among several agents and it already takes time to transfer data from one to another. Incidentally, all those agents also have to persist pieces of information and get them back when times arrive.</p> <p>It feels rather natural to guarantee a high availability on each storage. Furthermore, the network doesn’t have a complicated and evolved database scheme. What is needed is merely a map which links a given key to one or several entries. Deploying an <code>sql</code> server would be effective yet not efficient. Even though solutions like <a href="http://redis.io/">Redis</a> or <a href="http://leveldb.org/">levelDB</a> grasped our interest at first (they are tried and tested in-memory databases), we eventually turn towards <a href="https://github.com/boltdb/bolt">boltDB</a> which is a robust <em>Go</em> in-memory storage. Three essential reasons drive that choice:</p> <ul> <li> <p>Bolt’s design is extremely simple: it maps keys (raw sequence of bytes) to values (raw sequence of bytes as well).</p> </li> <li> <p>Despite its relatively poor performances for writing, Bolt is fast enough for reading. The network experiences way more lookups than updates, hence Bolt.</p> </li> <li> <p>Bolt is written in <em>Go</em> and offers a wonderful <em>Go</em> library, completely effortless for us to use.</p> </li> </ul> <p><img src="/img/articles/ttn/chart_db.png" alt="In-memory backend performances comparison" /></p> <p>There’s still one downside about using Bolt. We cannot (at least directly) manipulate the storage from a cluster of components. For instance, this entails one router is bound to one database. Should we want to deploy a cluster of routers behind a balancer which all share the same storage, we need to build all the necessary mechanisms on top of Bolt (mechanisms that are already included in tools like Redis). There’s nevertheless nothing wrong in evolving from Bolt to something else. One can even plug an extra backend manager like <a href="http://ledisdb.com/">LedisDB</a> which would extend Bolt’s functionality to enable a distributed processing through cluster. Moving from Bolt to Redis is also a realistic option.</p> <h3 id="testing-strategy">Testing strategy</h3> <p>I remember when I first heard about interfaces in <em>OO</em>, it sounded extremely weird to me. Then one day, I tried to test a piece of software and all of a sudden I realized for what interfaces were useful. By the by, almost everything in <em>Go</em> is about interacting with interfaces. They are implicitely implemented in the language and rather straightforward to declare. Once the code is built with them, it becomes a deeply and easily testable application, mostly because one is able to mock real entities with something on which the tester has a huge control. I previously explained how components (or operational objects) were solely composed of other operational objects though I didn’t mentioned that all dependencies were injected during the component instantiation such that it’s seemingly possible to declare a component full of fake internal components.</p> <figure class="highlight"><pre><code class="language-go" data-lang="go"><span class="c1">// Actual interface</span>
<span class="kd">type</span> <span class="nx">MyInterface</span> <span class="kd">interface</span><span class="p">{</span>
    <span class="nx">MyMethod</span><span class="p">(</span><span class="nx">arg1</span> <span class="kt">int</span><span class="p">,</span> <span class="nx">arg2</span> <span class="kt">string</span><span class="p">)</span> <span class="p">(</span><span class="kt">int</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span>
<span class="p">}</span>

<span class="c1">// Mock type</span>
<span class="kd">type</span> <span class="nx">MockMyInterface</span> <span class="kd">struct</span> <span class="p">{</span>
    <span class="nx">InMyMethod</span> <span class="kd">struct</span> <span class="p">{</span>
        <span class="nx">Arg1</span> <span class="kt">int</span>
        <span class="nx">Arg2</span> <span class="kt">string</span>
    <span class="p">}</span>
    <span class="nx">OutMyMethod</span> <span class="kd">struct</span> <span class="p">{</span>
        <span class="nx">Value</span> <span class="kt">int</span>
        <span class="nx">Error</span> <span class="kt">error</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="c1">// MyMethod implements the MyInterface interface</span>
<span class="kd">func</span> <span class="p">(</span><span class="nx">m</span> <span class="o">*</span><span class="nx">MockMyInterface</span><span class="p">)</span> <span class="nx">MyMethod</span><span class="p">(</span><span class="nx">arg1</span> <span class="kt">int</span><span class="p">,</span> <span class="nx">arg2</span> <span class="kt">string</span><span class="p">)</span> <span class="p">(</span><span class="kt">int</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
    <span class="nx">m</span><span class="p">.</span><span class="nx">InMyMethod</span><span class="p">.</span><span class="nx">Arg1</span> <span class="p">=</span> <span class="nx">arg1</span>
    <span class="nx">m</span><span class="p">.</span><span class="nx">InMyMethod</span><span class="p">.</span><span class="nx">Arg2</span> <span class="p">=</span> <span class="nx">arg2</span>
    <span class="k">return</span> <span class="nx">m</span><span class="p">.</span><span class="nx">OutMyMethod</span><span class="p">.</span><span class="nx">Value</span><span class="p">,</span> <span class="nx">m</span><span class="p">.</span><span class="nx">OutMyMethod</span><span class="p">.</span><span class="nx">Error</span>
<span class="p">}</span></code></pre></figure> <p>We consistently adopt the same strategy for each entity. We want to be able to drive each component the way we want: make them return a specific value or make them fail on demand. Sometimes, knowing the callee’s arguments is worth it. The snippet above shows how every mock has been implemented and the general principle behind them. During testing, it’s then under the tester responsability to provide the desired output to analyse the behaviour of the tested component.</p> <p>While looking at the mock’s structure, it seems rather obvious that the whole code could be generated. Interfaces are likely to evolve over time and even though it does’t require a lot of time to write or rewrite all corresponding mock interfaces, it’s still constitute time and effort that could be put into something else. Plus, once a generator has been proven, it saves a lot of unit tests and globally enhance the reliability of the application by removing codes. The least code one writes, the least bugs one’s likely to introduce.</p> <p>In the same idea, all the code needed to serialize and unserialize objects is remarkably similar. Moreover, it constitutes a critical part of the software: it needs to run quickly. To avoid repetitions, one is likely lured into a nice design which uses composition and / or inheritance patterns albeit this has a significant impact on performances. Another approach is to simply avoid writing this kind of code, and have it generated by a trusted library (so is <em>protobuf</em>). As a result, a lot of code in TTN is automatically generated. I see this as a mark of reliability. It’s less code to write, less code to maintain and less code to test. All of this makes us really focus on the core logic during testing. The next diagram gives an order of magnitude of the code’s distribution, might it be generated or manually written.</p> <p><img src="/img/articles/ttn/code_distribution.png" alt="Code Distribution" /></p> <h2 id="components-implementation">Components implementation</h2> <p>In this section, I want to explore of what the network core logic is really made. This implies to take each component and to look under the hood. During the introduction, I gave a general overview of the whole architecture. The next lines aim more at describing technically the implementation and the solutions adopted.</p> <h3 id="semtech-adapter">Semtech Adapter</h3> <p>The network starts with the Semtech adapter which receive and process <code>udp</code> datagrams sent by gateways. As it was stated above, the Router is merely an <code>rpc</code> server and thus, listens to <code>tcp</code> requests using an appropriate transport scheme and protocol. This adapter stands as a bridge between the external world and the network. Indeed, we have less control on the protocols defined in gateways’ firmware than on the network itself. The Semtech adapter enables a clear separation between the network core logic and the gateways such that we can totally change gateways protocol without any impact on the internal business logic.</p> <p>Therefore, it abstracts the Semtech protocol by taking care of replying accordingly to uplink datagrams: should you glance at the semtech protocol, you’ll notice that it defines a mechanism to keep a connection open (by nature, <code>udp</code> connections are not kept open and because routers might not be able to contact gateways directly, the connection needs to stay available during the whole communication). Those details have nothing to do with the network itself and shouldn’t be considired in the router. What really matters for the router are the actual uplink data or join-request, out of any <code>udp</code> context. The Semtech adapter is precisely playing that role, making sure the router is bothered only by actual TTN packets.</p> <p>Looking at the code, we can split it in three global parts. First of all, the <code>udp</code> server itself: the adapter plays the role of a server, listening to a specific port on which gateways can establish connections and send datagrams.</p> <figure class="highlight"><pre><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nx">listen</span><span class="p">(</span><span class="nx">netAddr</span> <span class="kt">string</span><span class="p">,</span> <span class="nx">conn</span> <span class="o">*</span><span class="nx">net</span><span class="p">.</span><span class="nx">UDPConn</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">for</span> <span class="p">{</span>
        <span class="c1">// 1. Read from connection</span>
        <span class="c1">// 1.1 In case of error, try to reconnect (exponential backoff-like algorithm)</span>
        <span class="k">go</span> <span class="kd">func</span><span class="p">(</span><span class="nx">data</span> <span class="p">[]</span><span class="kt">byte</span><span class="p">,</span> <span class="nx">conn</span> <span class="o">*</span><span class="nx">net</span><span class="p">.</span><span class="nx">UDPConn</span><span class="p">)</span> <span class="p">{</span>
            <span class="c1">// 2.1 Unmarshal Semtech packet</span>
            <span class="c1">// 2.2 Update connections pool</span>
            <span class="c1">// 2.3 Handle packet as PULL_DATA or PUSH_DATA</span>
        <span class="p">}(</span><span class="nx">data</span><span class="p">,</span> <span class="nx">conn</span><span class="p">)</span>
    <span class="p">}</span>
<span class="p">}</span></code></pre></figure> <p>Then, we handle packets as they arrive using five different methods. The first two methods use they three other to carry their tasks. In fact, an incoming uplink datagrams might contain more than one payload meaning that a single transfer between a gateway and a router is likely to lead to several uplink network packets (possibly of different natures). To make it clear, all calls have just been distributed among the following methods:</p> <ul> <li> <p><strong>handlePushData()</strong>: Processes a Semtech datagram and call <strong>handleUp</strong> for each rxpk packets carried by the Semtech datagram</p> </li> <li> <p><strong>handlePullData()</strong>: Acknowledges a Semtech <code>PULL_DATA</code> datagram</p> </li> <li> <p><strong>handleUp()</strong>: Processes an actual network packet which could be either a confirmed/unconfirmed data or a join request.</p> </li> <li> <p><strong>handleDataDown()</strong>: Analyses an <strong>handleUp</strong> response in case where the packet carried an uplink data</p> </li> <li> <p><strong>handleJoinAccept()</strong>: Analyses an <strong>handleUp</strong> response in case where the packet carried a join request.</p> </li> </ul> <p>As a result, those methods wire up Semtech datagrams to the network. They eventually use conversion method which interpret either a rxpk Semtech packet and translate it to a corresponding network packet, or in the othr way around, interpret a network packet and translate it to a txpk packet. We thereby defined two methods <strong>toLoRaWANPayload</strong> and <strong>newTXPK</strong> to operate the wiring. Because each packet comes alongside some metadata, one also needs to transfer and convert metadata. Those pieces of information evolve with the development and thus, we need reflection to read from and insert into the corresponding source / target. The Semtech package uses pointer fields to make a difference between zero-typed fields and undefined types (because in <em>Go</em>, any variable is initialized with its default zero-value which makes impossible to know whether a variable refers to an uninitialized data). Nevertheless, using <code>gRPC</code> forces all internal metadata to be plain types (no pointer here). Field names are aslo not likely to match albeit they are rather similar. We deal with this concern by using <em>Go</em> <a href="https://golang.org/pkg/reflect/#StructTag">struct-tags</a>. Hence, for instance, to inject metadata from a network packet to a txpk packet, we use the following small though not straightforward piece of code:</p> <figure class="highlight"><pre><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nx">injectMetadata</span><span class="p">(</span><span class="nx">xpk</span> <span class="kd">interface</span><span class="p">{},</span> <span class="nx">src</span> <span class="kd">interface</span><span class="p">{})</span> <span class="kd">interface</span><span class="p">{}</span> <span class="p">{</span>
	<span class="nx">m</span> <span class="o">:=</span> <span class="nx">reflect</span><span class="p">.</span><span class="nx">ValueOf</span><span class="p">(</span><span class="nx">src</span><span class="p">)</span>
	<span class="nx">x</span> <span class="o">:=</span> <span class="nx">reflect</span><span class="p">.</span><span class="nx">ValueOf</span><span class="p">(</span><span class="nx">xpk</span><span class="p">).</span><span class="nx">Elem</span><span class="p">()</span>
	<span class="nx">tx</span> <span class="o">:=</span> <span class="nx">x</span><span class="p">.</span><span class="nx">Type</span><span class="p">()</span>

	<span class="k">for</span> <span class="nx">i</span> <span class="o">:=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="p">&lt;</span> <span class="nx">tx</span><span class="p">.</span><span class="nx">NumField</span><span class="p">();</span> <span class="nx">i</span><span class="o">++</span> <span class="p">{</span>
		<span class="nx">t</span> <span class="o">:=</span> <span class="nx">tx</span><span class="p">.</span><span class="nx">Field</span><span class="p">(</span><span class="nx">i</span><span class="p">).</span><span class="nx">Tag</span><span class="p">.</span><span class="nx">Get</span><span class="p">(</span><span class="s">&quot;full&quot;</span><span class="p">)</span>
		<span class="nx">f</span> <span class="o">:=</span> <span class="nx">m</span><span class="p">.</span><span class="nx">FieldByName</span><span class="p">(</span><span class="nx">t</span><span class="p">)</span>
		<span class="k">if</span> <span class="nx">f</span><span class="p">.</span><span class="nx">IsValid</span><span class="p">()</span> <span class="o">&amp;&amp;</span> <span class="nx">f</span><span class="p">.</span><span class="nx">Interface</span><span class="p">()</span> <span class="o">!=</span> <span class="nx">reflect</span><span class="p">.</span><span class="nx">Zero</span><span class="p">(</span><span class="nx">f</span><span class="p">.</span><span class="nx">Type</span><span class="p">()).</span><span class="nx">Interface</span><span class="p">()</span> <span class="p">{</span>
			<span class="nx">p</span> <span class="o">:=</span> <span class="nx">reflect</span><span class="p">.</span><span class="nx">New</span><span class="p">(</span><span class="nx">f</span><span class="p">.</span><span class="nx">Type</span><span class="p">())</span>
			<span class="nx">p</span><span class="p">.</span><span class="nx">Elem</span><span class="p">().</span><span class="nx">Set</span><span class="p">(</span><span class="nx">f</span><span class="p">)</span>
			<span class="k">if</span> <span class="nx">p</span><span class="p">.</span><span class="nx">Type</span><span class="p">().</span><span class="nx">AssignableTo</span><span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">Field</span><span class="p">(</span><span class="nx">i</span><span class="p">).</span><span class="nx">Type</span><span class="p">())</span> <span class="p">{</span>
				<span class="nx">x</span><span class="p">.</span><span class="nx">Field</span><span class="p">(</span><span class="nx">i</span><span class="p">).</span><span class="nx">Set</span><span class="p">(</span><span class="nx">p</span><span class="p">)</span>
			<span class="p">}</span>
		<span class="p">}</span>
	<span class="p">}</span>

	<span class="k">return</span> <span class="nx">xpk</span>
<span class="p">}</span></code></pre></figure> <h3 id="router-1">Router</h3> <p><img src="/img/articles/ttn/router.png" alt="Router illustrated" /></p> <p>The router’s role is fondamentally what we could expect from a load-balancer. It redirects the traffic to the appropriate recipient. At this stage, the network merely knows the device address associated to the packet (which is likely to conflict with another address). In the meanwhile, routers also monitor gateways: they process status packet from gateways and keep track of the time-on-air spent by each transmitter. They distill these pieces of information and communicate only the bare minimum to the rest of the chain.</p> <p>A router is split into three main parts that are quite close. They actually have been separated to enhance readibility and clarity. Here’s what it looks like:</p> <figure class="highlight"><pre><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nx">HandleStats</span><span class="p">(</span><span class="nx">request</span><span class="p">)</span> <span class="p">(</span><span class="nx">response</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 1. Validate request</span>
    <span class="c1">// 2. Update gateway statistics</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nx">HandleJoin</span><span class="p">(</span><span class="nx">request</span><span class="p">)</span> <span class="p">(</span><span class="nx">response</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 1. Validate request</span>
    <span class="c1">// 2. Add gateways statistics to request</span>
    <span class="c1">// 3. Broadcast the request</span>
    <span class="c1">// 4. Update gateway statistics</span>
    <span class="c1">// 5. Forward response to semtech adapter</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nx">HandleData</span><span class="p">(</span><span class="nx">request</span><span class="p">)</span> <span class="p">(</span><span class="nx">response</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 1. Validate request</span>
    <span class="c1">// 2. Add gateways statistics to request</span>
    <span class="c1">// 3. Lookup known brokers for corresponding device address</span>
    <span class="c1">// 4. Forward (if some brokers has been found) or broadcast the request</span>
    <span class="c1">// 5. In case of broadcasting, store any broker that acknowledges the request</span>
    <span class="c1">// 6. Update gateway statistics</span>
    <span class="c1">// 7. Forward the response, if any, to semtech adapter</span>
<span class="p">}</span></code></pre></figure> <p>The router is really straightforward. Its implementation has been kept short and simple. Almost all the logic has been put in the <em>duty cycle Manager</em> and in the <em>Broker</em> such that we consider the router only as a transition component which filters and redirects incoming messages.</p> <h3 id="duty-cycle-manager">Duty cycle manager</h3> <p>Because of band usage regulation per region (US, Europe, China …), the network has to monitor its outputs to make sure that the different transmitters don’t exceed limits defined by the authorities. The duty cycle manager precisely serves this purpose. It keeps track of transmitters and give an indication of a sub-band usage over time.</p> <p>Before any further computation, the managers expects to be configured with a set of sub-bands and a corresponding set of maximum duty cycles. Then, given a frequency in <code>MHz</code>, a payload size in number of bytes a data rate identifier and coding rate identifier, it can compute the time-on-air required to transfer a message.</p> <p>By the by, the duty cycle is a ratio which illustrates, for a given logical signal, whether the signal is up or down. For instance, a duty cycle of <code>0.5</code> indicates that 50% of the time, the signal is up (or down, as you wish). This implies an idea of time or more exactly, an idea of duration. What is actually computed by the manager is a duty cycle throughout a fixed interval of time (the duty cycle is therefore an average duty cycle over that interval). As soon as one considers a fixed interval, then, given a maximum duty cycle, one can compute the amount of time allocated for that period.</p> <p>Considering an interval of one hour, with a maximum duty cycle of <code>1%</code>, we end up with <code>36s</code> of availability each hour. If a transmitter reaches this limit in its first ten minutes, it would wait for fifty minutes before being allowed to transmit again. Limitations vary with the considered sub-band, and sub-bands vary with the world region in which the transmitter is located.</p> <p><img src="/img/articles/ttn/dutycycle.png" alt="duty cycles illustrated" /></p> <p>For a given transmitter, the manager indicates the transmitter usage with a percentage (ideally, a number between <code>0</code> and <code>100</code>, seldom above <code>100</code> should the transmitter breaks the limit). Because we don’t really need that granularity yet, we only consider four different states for transmitter on a given sub-band:</p> <ul> <li><strong>Blocked:</strong> usage is greater or equal to 100</li> <li><strong>Critical:</strong> usage is above 85 but still lower than 100</li> <li><strong>Available:</strong> usage is between 30 and 85</li> <li><strong>Highly available:</strong> usage is lower than 30</li> </ul> <p>Using these states, a signal noise ratio, and a signal strength, it is possible to compute a score for a given transmission. In a practical use case, a node emits a message on a frequency; that message might be caught by several gateways which will all forward the signal to the routers to which they are connected. At some point, all the messages get dispatched to one single handler. As a consequence, to each message is associated a given transmitter (gateway), and only one of them shall be used for a hypothetical reply. In practice, the handler uses the duty cycle manager to compute a score based on each message’s metadata. The priority is given to the transmitter state, then to the signal noise ratio and finally to the signal strength. The heuristic is extremely simple and is just used to sort transmitters at different stages, using those criteria.</p> <h3 id="broker">Broker</h3> <p>Similarly to how the router is designed, the TTN broker is merely a <code>tcp</code> server (or more exactly, two <code>tcp</code> servers running side-by-side; this allows a decoupling between network and monitoring communications). It offers two remote methods to handle data uplinks and join requests. In addition, the broker also manages applications and, for this purpose, relies on oAuth 2.0 protocol. Indeed, the broker might receive orders from an application (a handler being used to mediate the transmission) for which it would expect an identification token to be sent alongside. The broker is eventually linked to an in-memory local storage in which it can store information about applications and running end-devices.</p> <p>The broker handles data and join-request in a similar fashion, considering the following pseudo-code:</p> <figure class="highlight"><pre><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nx">HandleData</span><span class="p">(</span><span class="nx">request</span><span class="p">)</span> <span class="p">(</span><span class="nx">response</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 1. Validate request</span>
    <span class="c1">// 2. Retrieve associated entries, if any</span>
    <span class="k">for</span> <span class="nx">entry</span> <span class="o">:=</span> <span class="k">range</span> <span class="nx">entries</span> <span class="p">{</span>
        <span class="c1">// 3.1 Evaluate frame counter as a 16-bit counter</span>
        <span class="c1">// 3.2 Check MIC</span>
        <span class="c1">// 3.2.1 If MIC fails, evaluate frame counter as a 32-bit counter and check again</span>
        <span class="c1">// 3.3 If MIC check succeed, consider this entry and move along</span>
    <span class="p">}</span>
    <span class="c1">// 4. Update the frame counter associated to the device found</span>
    <span class="c1">// 5. Forward the request to the corresponding handler</span>
    <span class="c1">// 6. Analyze the response; if any, set the MIC and forward it to the router</span>
<span class="p">}</span>

<span class="kd">func</span> <span class="nx">HandleJoin</span><span class="p">(</span><span class="nx">request</span><span class="p">)</span> <span class="p">(</span><span class="nx">response</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 1. Validate request</span>
    <span class="c1">// 2. Retrieve previously used devNonce</span>
    <span class="c1">// 3. Check whether the devNonce has already been used</span>
    <span class="c1">// 4. Forward the request to the appropriated handler</span>
    <span class="c1">// 5. Analyze the response; if any, store the session keys and the devNonce used</span>
<span class="p">}</span></code></pre></figure> <p>Next to that, the broker is also used as a remote authority to control management operation on devices and applications. Each broker is able to verify the legitimacy of a request which provides a bearer token. As a matter of fact, the broker is in tight communication with a token provider, the same one that authenticates a user of an application by providing a valid token. Although applications don’t interact directly with brokers, they can emit request through a handler which will forward them on their behalf to an associated broker. The scheme is merely a close loop of communication where at the end, the broker ends up asking the token provider whether a user request shall be granted.</p> <p><img src="/img/articles/ttn/broker.png" alt="" /></p> <h3 id="handler-1">Handler</h3> <p>Last component properly said of the network infrastructure, the handler is responsible for making the life of applications easier. It should be clear though that many implementations of handlers might exist, I am going to argue about the “official” one TTN provides as an illustration of <em>what could be</em> a handler. Again, handlers simplify applications’ job yet the latter are likely to have different needs. We’ll hereby call handler the TTN handler in the next lines.</p> <p>The handler is a rather complicated set of intrinsic communications. It has indeed to buffer and temporize the processing of packets. All packets are forwaded and carried by other network components but because several gateways might transfer a received datagram originally, we need to catch them all and deduplicate the whole bundle in the handler. To carry out such a task, it defines two internal sub-processes <strong>consumeSet</strong> (C1) and <strong>consumeBundles</strong> (C2) which runs independently in their own goroutine. The former actually buffer an incoming packet into a queue and set an alarm since the first reception. The latter is triggered once a set of packets is ready to be processed (meaning, once the alarm previously set rang). Most of the business logic is located in the <strong>consumeBundles</strong> process in charge of deduplicating the request and publishing the result.</p> <p>The handler also defines, like other core components, <code>rpc</code> methods intended to be called remotely. These methods work in pair with the two sub-processes which, by taking advantage of <em>Go</em> channels’ nature, enables a synchronous and quite straightforward operation. For instance:</p> <figure class="highlight"><pre><code class="language-go" data-lang="go"><span class="kd">func</span> <span class="nx">HandleDataUp</span><span class="p">(</span><span class="nx">request</span><span class="p">)</span> <span class="p">(</span><span class="nx">response</span><span class="p">,</span> <span class="kt">error</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// 1. Validate request</span>
    <span class="c1">// 2. Retrieve device data from AppEUI + DevEUI</span>
    <span class="c1">// 3. Wrap packet into a &quot;bundle&quot; and set a new uplink entry</span>
    <span class="c1">// 4. Wait for the bundle to be processed</span>
    <span class="c1">// 5. If any, forward the response to the broker </span>
<span class="p">}</span></code></pre></figure> <p>What is called <em>bundle</em> is actually a super-set of an uplink packet (or similarly, a join-request). As well as holding the packet itself and a unique identifier, the bundle also carries a channel that should be used to reply to the routine that is processing the uplink (and this is incidentally where the <strong>HandleDataUp</strong> and <strong>HandleJoin</strong> magically become synchronous methods).</p> <p><img src="/img/articles/ttn/handler.png" alt="" /></p> <p>For class A devices, LoRaWAN also allows the application to reply to an uplink. However, carrying a datagram from a gateway up to the application already requires time. Moreover, if a downlink has to be sent, it should be within a second (considering one started to count since a datagram reaches a gateway), or maybe two seconds should we target the second response window. That’s a short time frame, and applications aren’t likely to provide such a level of availability. In order to cope with this issue, we allow applications to “schedule” downlink for a specific device. Indeed, one can push a perishable packet into a queue. When appropriated, the handler might grab one from the queue and use it as the response’s frame payload. Beside, in case where no packet has been scheduled but a response is nonetheless needed (most likely because the uplink packet was a <em>Confirmed Data Up</em>), the handler will generate a response carrying an empty frame payload.</p> <p>By the by, the handler is also in charge of encrypting and decrypting either frame payloads or join-accept responses. It is incidentally holding application private keys and is able to (has to) generate new session keys on each join-request. By dealing with these tasks, the handler becomes a rather complicated component: loads of operations require access to session keys hence being the only bearer necessarily empowers it as well as makes it a major point of business logic. Although it was originally designed to serve applications with a low coupling to the network, the handler has become an important piece of software on which key elements now rely. We’re looking forward to moving as much logic as possible in the broker and the router. This way, the broker would remain the only heavy component of the network.</p> <h3 id="mqtt-adapter">MQTT Adapter</h3> <p>Last piece of the network, the <code>mqtt</code> adapter has a similar role to the semtech adapter previously presented. It enables the communication between the network and an <code>mqtt</code> broker in such a way that it is transparent for the network. Again, we’re here using <code>rpc</code> to deal with this problem. I’ll not dive into the <code>mqtt</code> protocol; it wouldn’t be relevant at all. The adapter is straightforward and merely describe two remote methods <code>HandleData</code> and <code>HandleJoin</code>. Under the hood, it’s just a way for the handler to publish messages on <code>mqtt</code> topics without having to deal with the topics itself.</p> <h2 id="looking-ahead">Looking ahead</h2> <p>The network is still in its early stages. We’re now on the verge of opening the staging environment to the wild world. It doesn’t contain all the expected features though. Some work is still required to handle <code>mac</code> commands as defined in LoRaWAN. Also, as we built the network, we noticed issues and improvement that could be made on the original architecture. Our mission is now to make it easy to use and safe for users and developers. We’re thereby striving to provide as many services as we can while in the meanwhile, we work hard on improving the quality of the existing network. In the nineties, they were building the Internet. Now, we put all out efforts into building the Internet Of Things.</p> </div> </article> <footer class="site-footer"> <div class="container"> <ul class="social"> <li><a href="http://github.com/KtorZ" target="_blank"><i class="icon icon-github"></i></a></li> <li><a href="http://linkedin.com/in/matthias-benkort-47186a57" target="_blank"><i class="icon icon-linkedin"></i></a></li> <li><a href="http://twitter.com/mbenkort" target="_blank"><i class="icon icon-twitter"></i></a></li> </ul> <p> <small>&copy;2016 All rights reserved. Made with <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> and ♥</small> </p> </div> </footer> </main> <script src="/assets/js/jquery-2.1.1.js"></script> <script src="/assets/js/main.js"></script> </body> </html><!-- by nandomoreira.me -->